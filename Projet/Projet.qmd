---
title: "Projet Statistique avec R"
author: "ABOTSI Kossi Tonyi Wobubey"
date: "`r Sys.Date()`"
output: html_document
editor: visual
---

### INTRODUCTION

Ce projet se divise en deux principales sections. La premi√®re est d√©di√©e √† la mod√©lisation d'une s√©rie temporelle et √† la pr√©vision des prix pour l'ann√©e 2024. La seconde vise √† √©laborer un mod√®le qui √©tablit un lien entre la mortalit√© attribuable √† la pollution atmosph√©rique et la consommation par habitant de diff√©rents types d'√©nergie. Dans le cadre de ce projet, tous les tests statistiques seront r√©alis√©s avec un seuil de signification de $\alpha = 5\%$**.**

### Chargement des packages necessaire pour le projet

```{r warning=FALSE,message=FALSE,error=FALSE}
#Package pacman installe et charge les packages m√™mes s'ils ne sont pas dans notre environement de d√©veloppement.
if(!require(pacman)) install.packages('pacaman')

pacman::p_load(pacman, readr, lubridate, tseries, forecast, tidyverse, plotly,lmtest,car,MASS,latex2exp,openxlsx,sandwich,ggfortify,GGally,broom)
```

## Exercice I :

#### A-Imporation des donn√©es

```{r}
 data_Poland <- read.csv("Poland.csv")

 
 colnames(data_Poland)[4] = 'Date_local'
 colnames(data_Poland)[3] = 'Date_UTC'
 colnames(data_Poland)[5] = 'Prix'
 
 #Convertion en type date
 data_Poland$Date_local = ymd_hms(data_Poland$Date_local)
 head(data_Poland)
 
```

√âtant donn√© que mes donn√©es sont extr√™mement d√©taill√©es, √©tant collect√©es par heure, cela peut compliquer l'ajustement d'un mod√®le en raison de la complexit√© de la s√©rie temporelle. De plus, mon objectif est de r√©aliser des pr√©visions des prix moyens mensuels pour l'ann√©e 2024.

Par cons√©quent, plut√¥t que de travailler avec des donn√©es horaires, je choisis d'agr√©ger ces donn√©es sur une base mensuelle. Cette approche r√©duira la granularit√© des donn√©es, ce qui pourrait faciliter consid√©rablement l'ajustement du mod√®le.

```{r}
# Agr√©ger les donn√©es quotidiennes des prix en Pologne par mois et calculer la moyenne des prix pour chaque mois
monthly_data_Poland <- aggregate(data_Poland$Prix, by = list(Date_local = format(data_Poland$Date_local, "%Y-%m")), FUN = mean)

# Renommer la deuxi√®me colonne en "Prix"
colnames(monthly_data_Poland)[2] <- "Prix"

# Convertir la date au format ymd
monthly_data_Poland$Date_local <- ym(monthly_data_Poland$Date_local)


# Afficher les premi√®res lignes des donn√©es
head(monthly_data_Poland)
write.xlsx(monthly_data_Poland, "mon_fichier_ts.xlsx", rowNames = FALSE)
```

### B-Visualisation graphique (Analyse de l'√©volution de la s√©rie)

```{r}
graphe <- ggplot(data = monthly_data_Poland, aes(x = Date_local, y = Prix)) +
  geom_line(color='blue') +
  theme_minimal() +
  labs(title = "Evolution du prix de l'electricit√©", x = "Temps (Ann√©e-Mois)", y = "Prix (Euro/Mwhe)") +
  scale_x_date(date_labels = "%Y-%m", date_breaks = "6 month") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),plot.title = element_text(hjust = 0.5))

#Convertir en graphique plotly pour l'interactivit√©
ggplotly(graphe)
```

Sur notre graphique, il est observable que la tendance g√©n√©rale des prix de l'√©lectricit√© reste relativement stable de 2015 √† 2020, mais conna√Æt une hausse notable entre 2021 et 2023. Suite √† cette p√©riode, les prix chutent, revenant √† des niveaux plus habituels. Cette augmentation significative des prix entre 2021 et 2023 pourrait √™tre attribu√©e en partie √† la pand√©mie de COVID-19, ainsi qu'aux cons√©quences de la guerre entre la Russie et l'Ukraine, 2022 marquant la premi√®re ann√©e de conflit avec un pic maximal √† 198.82 euros par m√©gawattheure.

### C-Mod√©lisation

#### Stationnarisation de notre s√©rie

Avant d'ajuster un mod√®le de s√©rie temporelle, il est essentiel de se demander si la s√©rie est stationnaire. Les s√©ries stationnaires, caract√©ris√©es par une stabilit√© de la moyenne, de la variance et de l'autocorr√©logramme, sont g√©n√©ralement plus faciles √† mod√©liser.

Concernant la s√©rie que nous examinons, des doutes sur sa stationnarit√© peuvent surgir, notamment en raison d'une tendance qui augmente puis diminue l√©g√®rement, accompagn√©e de variations importantes d'amplitude. Pour r√©duire cette variabilit√©, nous avons recours √† une transformation de Box-Cox.

Soit $(X_t)_t\in \mathbb{N}$ notre s√©rie initial,$(Y_t)_t\in \mathbb{N}$ la s√©rie transform√©e avec $Y_t = (X_t^\lambda-1)/\lambda$

```{r}
monthly_data_Poland_ts = ts(monthly_data_Poland$Prix,start=c(year(min(monthly_data_Poland$Date_local)),month(min(monthly_data_Poland$Date_local)),day(min(monthly_data_Poland$Date_local))),frequency =12)

box <- boxcox(monthly_data_Poland_ts ~ 1, lambda = seq(-1, 1, 1/10))
lambda <- box$x[which.max(box$y)]
lambda
```

Il est clair que la log-vraisemblance atteint son maximum lorsque $\lambda = -0.979798$.

Proc√©dons √† la transformation.

```{r}

monthly_data_Poland$Prix = ((monthly_data_Poland$Prix)^lambda-1)/lambda

monthly_data_Poland_ts = (monthly_data_Poland_ts^lambda-1)/lambda

graphe_2=ggplot(data = monthly_data_Poland, aes(x = Date_local, y = Prix)) +
  geom_line(color = 'blue') +
  theme_minimal() +
  labs(title = "Evolution du prix de l'electricit√© transform√©", x = "Temps (Ann√©e-Mois-Jour)", y = "Prix (Euro/Mwhe)") +
  scale_x_date(date_labels = "%Y-%m-%d", date_breaks = "6 month") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),plot.title = element_text(hjust = 0.5))

#Convertir en graphique plotly pour l'interactivit√©
ggplotly(graphe_2)

```

D√©composons notre s√©rie temporelle transform√©e, not√©e $(Y_t)_t\in \mathbb{Z}$ , afin de d√©terminer et d'extraire ses composantes de tendance et de saisonnalit√©.

```{r}
plot(decompose(monthly_data_Poland_ts))
```

Donc on voit clairement qu'on a une tendance polynomiale, accompagn√©e d'une composante saisonni√®re qui se r√©pete tous les 12 mois.

**Analysons la sortie acf de notre s√©rie** $Y_t$ **.**

```{r}
# Cr√©er les graphiques
par(mfrow = c(1, 2))  # Diviser la fen√™tre graphique en deux colonnes
acf = acf(na.omit(monthly_data_Poland_ts),plot = FALSE)
acf$lag <- acf$lag * 12
plot(acf, ylim = c(-1, 1),main=TeX("$Y_t$"))

pacf <- pacf(na.omit(monthly_data_Poland_ts), plot = FALSE)
pacf$lag <- pacf$lag * 12
plot(pacf, ylim = c(-1, 1),main=TeX("$Y_t$"))
```

Nous observons ici que la d√©croissance de cette sortie ACF est tr√®s lente. Sur cette base, nous pouvons conclure que notre s√©rie n'est pas stationnaire.

Pour confirm√© ou infirm√© mon intution que j'ai eu avec l'analyse visuel je fais le test de ***Dikey fuller pour la stationnarit√©***

**H0 : Il y a pr√©sence de racine unitaire**

**H1 : Il n'y a pas de racine unitaire**

```{r}
test_res = adf.test(monthly_data_Poland_ts,k=12)
test_res
```

J'obtiens une p-valeur de 0.4057, qui est sup√©rieure au seuil de 5% de mon test. Par cons√©quent, nous conservons l'hypoth√®se nulle H0‚Äã, ce qui me conduit √† conclure √† la pr√©sence d'une racine unitaire et, donc, √† la non-stationnarit√© de ma s√©rie.

Nous effectuons une diff√©renciation √† l'ordre 12 pour √©liminer la saisonnalit√©, ce qui nous donne la s√©rie $(I-B^{12})Y_t$, o√π B correspond √† l'op√©rateur de retard.

On obtient le graphique suivant :

```{r}
monthly_data_Poland_ts_dif_12 = diff(monthly_data_Poland_ts,lag=12,differences = 1)

plot(monthly_data_Poland_ts_dif_12,main=TeX("$(I-B^{12})Y_t$"))
```

Observons sa sortie acf :

```{r}
acf_2 = acf(na.omit(monthly_data_Poland_ts_dif_12),plot = FALSE)

acf_2$lag = acf_2$lag*12

plot(acf_2,ylim = c(-1,1),main=TeX("$(I-B^{12})Y_t$"))
```

Nous observons une d√©croissance toujours lente dans notre sortie ACF. Par cons√©quent, nous proc√©dons √† une diff√©renciation de premier ordre de la s√©rie, qui avait d√©j√† √©t√© diff√©renci√©e √† l'ordre 12, afin d'√©liminer la tendance. Nous obtenons ainsi la s√©rie suivante : $(I-B)(I-B^{12})Y_t$.

on obtient le graphe suivant :

```{r}
monthly_data_Poland_ts_dif_1 = diff(monthly_data_Poland_ts_dif_12,lag=1,differences = 1)

plot(monthly_data_Poland_ts_dif_1,main=TeX("$(I-B)(I-B^{12})Y_t$"))


```

Observons sa sortie acf :

```{r}
acf_2 = acf(na.omit(monthly_data_Poland_ts_dif_1),plot = FALSE)

acf_2$lag = acf_2$lag*12

plot(acf_2,ylim = c(-1,1),main=TeX("$(I-B)(I-B^{12})Y_t$"))
```

La sortie ACF de la s√©rie, apr√®s une double diff√©renciation, semble indiquer que nous avons affaire √† une s√©rie stationnaire. En effet, contrairement √† la d√©croissance lente observ√©e pr√©c√©demment, nous notons cette fois une d√©croissance rapide vers z√©ro dans notre autocorr√©logramme estim√©.

Je refais le test de ***Dikey fuller pour la stationnarit√©***

```{r}
adf.test(monthly_data_Poland_ts_dif_1)
```

J'obtiens une p-valeur de 0.01, qui est inf√©rieure au seuil de 5% de mon test, ce qui nous am√®ne √† rejeter l'hypoth√®se nulle ùêª0H0‚Äã. Par cons√©quent, notre s√©rie diff√©renci√©e $(I-B)(I-B^{12})Y_t$ peut √™tre potentiellement consid√©r√© comme stationnaire.

#### Ajustement d'un model sur le processus $(I-B)(I-B^{12})Y_t$ **et Prevision pour l'ann√©e 2024**

On veut ajuster un model ARMA sur la s√©rie $(I-B)(I-B^{12})Y_t$**.** On vas utiliser la m√©thode de ***Box et Jenkins*** dont les quatres √©tapes sont les suivantes :

-   **Identification**

-   **Estimation**

-   **Validation**

-   **Pr√©vision**

    **a-) Identification**

Les valeurs des param√®tres sont d√©termin√©es √† l'aide de l'autocorr√©logramme partiel et de l'autocorr√©logramme simple.

#### Autocorr√©logramme simple et Autocorr√©logramme partiel :

```{r}
# Cr√©er les graphiques
par(mfrow = c(1, 2))  # Diviser la fen√™tre graphique en deux colonnes
acf = acf(na.omit(monthly_data_Poland_ts_dif_1),plot = FALSE)
acf$lag <- acf$lag * 12
plot(acf, ylim = c(-1, 1),main=TeX("$(I-B)(I-B^{12})Y_t$"))

pacf <- pacf(na.omit(monthly_data_Poland_ts_dif_1), plot = FALSE)
pacf$lag <- pacf$lag * 12
plot(pacf, ylim = c(-1, 1),main=TeX("$(I-B)(I-B^{12})Y_t$"))
```

Sur l'autocorr√©logramme simple estim√©, nous observons un pic significatif au retard 1. De m√™me, la fonction d'autocorr√©lation partielle estim√©e r√©v√®le un pic significatif √† ce m√™me retard.

Ainsi, il est envisageable de proposer un premier mod√®le, **`model_1`**, qui serait un **SARIMA(1,1,1)(1,1,1)\[12\]**.

**b)Estimation et Validation**

Plusieurs mod√®les sont susceptibles de correspondre √† notre processus g√©n√©rateur de donn√©es. Le meilleur mod√®le, celui qui sera finalement choisi, sera d√©termin√© sur la base des crit√®res suivants :

-   La minimisation du crit√®re d'information d'Akaike (AIC).

-   La significativit√© des coefficients estim√©s.

-   La blancheur des r√©sidus, assurant que ces derniers ne pr√©sentent aucune autocorr√©lation.

**Estimation du mod√®le SARIMA(1,1,1)(1,1,1)\[12\] :**

On estime le mod√®le identifi√© **model_1**.

```{r}
model_1 = Arima(monthly_data_Poland_ts, order = c(1, 1, 1),list(order=c(1,1,1),period=12), method = "CSS-ML")
summary(model_1)
```

Proc√©dons aux tests de significativit√© des coefficients obtenus dans le mod√®le.

Les hypoth√®ses sont les suivantes :

-   **H0 (Hypoth√®se nulle)** : Le coefficient est nul.

-   **H1 (Hypoth√®se alternative)** : Le coefficient est diff√©rent de z√©ro.

**Significativit√© des coefficients du model_1**

```{r}
coeftest(model_1)
```

Les p-valeurs de certains coefficients ne sont pas toutes inf√©rieures au seuil de 5% du test, ce qui signifie que tous les coefficients ne sont pas significativement diff√©rents de z√©ro. Notamment, les coefficients **`ar1`**, **`ma1`** et **`sar1`** ne se distinguent pas significativement de z√©ro, car leurs p-valeurs ne sont pas inf√©rieures √† 5%. Par cons√©quent, nous √©liminons le param√®tre le moins significatif, **`sar1`**, et r√©examinons le mod√®le ainsi modifi√©.

Consid√©rons donc **`model_2`**, le nouveau mod√®le obtenu, qui est un **SARIMA(1,1,1)(0,1,1)\[12\]**.

On estime **model_2**

```{r}
model_2 = Arima(monthly_data_Poland_ts, order = c(1, 1, 1),list(order=c(0,1,1),period=12), method = "CSS-ML")
summary(model_2)
```

Proc√©dons au test de significativit√© des coefficients obtenus dans le mod√®le.

```{r}
coeftest(model_2)
```

Nous obtenons un mod√®le dont l'AIC est inf√©rieur √† celui de **`model_1`**, et nous constatons √† nouveau que deux des param√®tres ne sont pas significatifs. Il s'agit des coefficients **`ar1`** et **`ma1`**, dont les p-valeurs restent inf√©rieures √† 5%. Nous √©liminons donc du mod√®le le param√®tre le moins significatif, **`ar1`**.

En suivant la m√™me m√©thode que pr√©c√©demment, nous allons maintenant tester **`model_3`**, qui est un **SARIMA(0,1,1)(0,1,1)\[12\]**.

```{r}
model_3 = Arima(monthly_data_Poland_ts, order = c(0, 1, 1),list(order=c(0,1,1),period=12), method = "CSS-ML")
summary(model_3)
```

Proc√©dons au test de significativit√© des coefficients obtenus dans le mod√®le.

```{r}
coeftest(model_3)
```

Nous constatons que les deux coefficients de ce mod√®le sont significatifs, car les p-valeurs de ce test de significativit√© sont toutes inf√©rieures √† 5%, et l'AIC de ce mod√®le est √©galement inf√©rieur √† ceux des deux mod√®les pr√©c√©dents.

Il reste maintenant √† v√©rifier si les r√©sidus de notre mod√®le estim√© correspondent √† un bruit blanc, c'est-√†-dire √† une s√©rie temporelle normalement distribu√©e, avec une moyenne de z√©ro, sans autocorr√©lation et homosc√©dastique. Voici quelques points √† v√©rifier :

-   **Nullit√© de la moyenne**

Calculons la moyenne de nos r√©sidus :

```{r}
mean(model_3$residuals)
```

La moyenne est extr√™mement proche de z√©ro, ce qui nous permet de conclure √† la nullit√© de la moyenne des r√©sidus.

-   **Test de pr√©sence d'autocorr√©lation**

    Nous effectuons le test de Ljung-Box sur les r√©sidus du mod√®le.

    Les hypoth√®ses sont les suivantes :

    -   **H0 (Hypoth√®se nulle)** : Les r√©sidus ne sont pas autocorr√©l√©s.

    -   **H1 (Hypoth√®se alternative)** : Les r√©sidus sont autocorr√©l√©s.

    Voici la commande :

    ```{r}
    resultat = data.frame(Order = integer(),Statistic_test=numeric(),P_valeur=numeric())

    #Application du test de Ljung-Box pour diff√©rent ordre

    for (i in 1:12)
    {
      test_resultat = Box.test(model_3$residuals,lag = i*6,type = "Ljung-Box")
      resultat = rbind(resultat,data.frame(Order=i*6,Statistic_test = test_resultat$statistic,P_valeur = test_resultat$p.value))
    }

    resultat

    ```

Pour ces diff√©rents retards, nous constatons que les p-valeurs ne sont pas inf√©rieures au seuil de 5% du test. Par cons√©quent, nous ne pouvons pas rejeter l'hypoth√®se nulle selon laquelle les r√©sidus ne sont pas autocorr√©l√©s.

-   **Normalit√© des r√©sidus**

Observons le QQ-plot pour √©valuer la normalit√© des r√©sidus de notre mod√®le.

```{r}
qqnorm(model_3$residuals)
qqline(model_3$residuals)
```

Nous observons que la majorit√© des points se concentrent autour de la droite th√©orique, √† l'exception de quelques points situ√©s dans les queues de la distribution. Sur cette base, nous pouvons conclure √† la normalit√© des r√©sidus.

Confirmons cette observation avec le test de **Shapiro-Wilk**. Les hypoth√®ses pour ce test sont les suivantes :

-   **H0 (Hypoth√®se nulle)** : Les donn√©es suivent une distribution normale.

-   **H1 (Hypoth√®se alternative)** : Les donn√©es ne suivent pas une distribution normale.

```{r}
shapiro.test(model_3$residuals)
```

Nous obtenons une p-valeur de 0.6473, qui est sup√©rieure au seuil de 5%, donc nous ne pouvons pas rejeter l'hypoth√®se nulle H0‚Äã. Ainsi, nous consid√©rons que le test de normalit√© est v√©rifi√©.

-   **Homosc√©dasticit√©**

Nous utilisons le test de Breusch-Pagan pour √©valuer l'homog√©n√©it√© de la variance des erreurs. Les hypoth√®ses de ce test sont les suivantes :

-   **H0 (Hypoth√®se nulle)** : La variance des erreurs est constante (Homosc√©dasticit√©).

-   **H1 (Hypoth√®se alternative)** : La variance des erreurs n‚Äôest pas constante (H√©t√©rosc√©dasticit√©).

```{r}
residu=model_3$residuals
test_bp = bptest(residu~fitted(model_3)+I(fitted(model_3)^2),data = data.frame(residu,fitted(model_3)))

print(test_bp)
```

√âtant donn√© que la **p-valeur est de 0.2363, qui est sup√©rieure au seuil de 5%, nous ne pouvons pas rejeter l'hypoth√®se nulle.** Cela indique que la variance des r√©sidus n'est pas d√©pendante des valeurs ajust√©es par le mod√®le ou de leurs carr√©s, conform√©ment aux pr√©dicteurs inclus dans le mod√®le de r√©gression des carr√©s des r√©sidus. Nous pouvons donc conclure √† l'homosc√©dasticit√© des r√©sidus.

Toutes les hypoth√®ses √©tant donc v√©rifi√©es, visualisons l'ACF des r√©sidus.

**Visualisons l'acf des r√©sidus**

```{r}
acf_=acf(model_3$residuals,plot=FALSE)
acf_$lag = acf_$lag * 12

plot(acf_,ylim = c(-1, 1),main="R√©sidus")
```

En r√©sum√©, l'analyse des r√©sidus a confirm√© que notre mod√®le r√©pond aux hypoth√®ses de normalit√© et d'homosc√©dasticit√©. Les tests de Shapiro-Wilk et de Breusch-Pagan ont valid√© que les r√©sidus sont normalement distribu√©s et pr√©sentent une variance constante, assurant ainsi l'ad√©quation du mod√®le. De plus, l'inspection de l'ACF des r√©sidus ne montre aucun pic significatif, indiquant que les r√©sidus sont effectivement des bruits blancs.

Nous avons donc √©tabli un mod√®le SARIMA(0,1,1)(0,1,1)\[12\] qui s'av√®re convenable. √Ä partir de ce mod√®le, nous pouvons d√©sormais effectuer des pr√©visions.

**c)Pr√©diction**

Pour nous assurer de la qualit√© pr√©dictive de notre mod√®le, nous pouvons effectuer une analyse √† post√©riori.

Nous tronquons la s√©rie pour les ann√©es 2022 et 2023, que nous cherchons ensuite √† pr√©voir en utilisant l'historique de 2015 √† 2021. Estimons donc notre mod√®le sur cette s√©rie tronqu√©e.

```{r}
#S√©rie temporelle jusqu'√† 2022
data_tronc = window(monthly_data_Poland_ts,end=c(2021,12))
#Serie temporelle en 2023
data_a_prevoir = window(monthly_data_Poland_ts,start=c(2022,1),end=c(2023,12))

model_3_tronc = Arima(data_tronc,order = c(0, 1, 1),list(order=c(0,1,1),period=12), method = "CSS-ML")

summary(model_3_tronc)

```

V√©rifions que ce mod√®le est toujours convenable sur la s√©rie tronqu√©e, c'est-√†-dire que les r√©sidus peuvent toujours √™tre consid√©r√©s comme un bruit blanc.

**Autocorr√©lation des r√©sidus**

Nous effectuons le test de Ljung-Box sur les r√©sidus du mod√®le.

```{r}
resultat = data.frame(Order = integer(),Statistic_test=numeric(),P_valeur=numeric())

#Application du test de Ljung-Box pour diff√©rent ordre

for (i in 1:12)
{
  test_resultat = Box.test(model_3_tronc$residuals,lag = i*6,type = "Ljung-Box")
  resultat = rbind(resultat,data.frame(Order=i*6,Statistic_test = test_resultat$statistic,P_valeur = test_resultat$p.value))
}

resultat
```

Pour ces diff√©rents retards, nous constatons que les p-valeurs ne sont pas inf√©rieures au seuil de 5%, donc nous ne pouvons pas rejeter l'hypoth√®se nulle selon laquelle les r√©sidus ne sont pas autocorr√©l√©s.

**Normalit√© du r√©sidu sur la s√©rie tronqu√©**

Proc√©dons √† l'ex√©cution du test de **Shapiro-Wilk** :

```{r}
shapiro.test(model_3_tronc$residuals)
```

Nous obtenons une p-valeur de 0.4397, qui est sup√©rieure au seuil de 5%, donc nous ne pouvons pas rejeter l'hypoth√®se nulle (H0). Ainsi, nous consid√©rons que le test de normalit√© est v√©rifi√©.

**Homosc√©dascticit√© :**

Proc√©dons √† l'ex√©cution du test de **Breusch-Pagan** :

```{r}
residu=model_3_tronc$residuals
test_bp = bptest(residu~fitted(model_3_tronc)+I(fitted(model_3_tronc)^2),data = data.frame(residu,fitted(model_3_tronc)))

print(test_bp)
```

La p-valeur est de 0.2107, ce qui est sup√©rieur au seuil de 5% fix√© pour le niveau de test, donc nous ne pouvons pas rejeter l'hypoth√®se nulle (H0). Nous pouvons donc conclure √† l'homosc√©dasticit√© des r√©sidus de ce mod√®le tronqu√©.

**Visualisons l'acf des r√©sidus**

```{r}
acf_r=acf(model_3_tronc$residuals,plot=FALSE)
acf_r$lag = acf_r$lag * 12

plot(acf_r,ylim = c(-1, 1),main="R√©sidus mod√®le tronqu√©")
```

Nous observons sur cette sortie ACF qu‚Äôil n‚Äôy a aucun pic significatif, ce qui me permet de conclure √† l'homosc√©dasticit√© des r√©sidus et de confirmer qu'ils constituent un bruit blanc.

Nous superposons maintenant les donn√©es des ann√©es 2022 et 2023 avec les pr√©visions obtenues √† partir de l'historique de 2015 √† 2021.

```{r}
pred_model_3_tronc = forecast(model_3_tronc,h=24,level = 95)


pred_tronc = ts(pred_model_3_tronc$mean,start = c(2022,1),frequency = 12)

pred_l_tronc = ts(pred_model_3_tronc$lower,start = c(2022,1),frequency = 12)

pred_u_tronc = ts(pred_model_3_tronc$upper,start = c(2022,1),frequency = 12)

#ts.plot(data_a_prevoir)
ts.plot(data_a_prevoir,pred_tronc,pred_u_tronc,pred_l_tronc,xlab='t',ylab='Prix ',main="Prix mensuel moyen de l'√©lectricit√©",col=c(1,2,3,3),lty=c(1,1,2,2),lwd=c(3,3,2,2))

legend("topleft",legend=c("X","X_prev"),col=c(1,2,3,3),lty=c(1,1),lwd=c(3,3))
legend("topright",legend=c("int95%_inf","int95%_sup"),col=c(3,3),lty=c(2,2),lwd=c(2,2))
```

Nous constatons que la pr√©vision, repr√©sent√©e en rouge, est proche de la r√©alit√©, affich√©e en noir, et que l'intervalle de pr√©vision englobe bien les r√©alisations observ√©es.

Cela renforce notre confiance en la qualit√© pr√©dictive de notre mod√®le et des pr√©visions qui pourront s'ensuivre √† partir du d√©but de l'ann√©e 2024.

#### Pr√©vision pour l'ann√©e 2024 :

Voici le graphe :

```{r}
pred_model=forecast(model_3,h=9,level=95)
pred=(pred_model$mean*lambda + 1)^(1/lambda)
pred_l=ts((pred_model$lower*lambda + 1)^(1/lambda),start=c(2024,4),frequency=12)
pred_u=ts((pred_model$upper*lambda + 1)^(1/lambda),start=c(2024,4),frequency=12)

ts.plot((monthly_data_Poland_ts*lambda + 1)^(1/lambda),pred,pred_l,pred_u,xlab="t",ylab="Prix (Euro/Mwhe)",col=c(1,2,3,3),lty=c(1,1,2,2),lwd=c(1,3,2,2),main="Pr√©vision du prix moyen mensuel de l'√©lectricit√© en Pologne")
```

En faisant un zoom sur la zone de pr√©diction on a :

```{r}
ts.plot(window((monthly_data_Poland_ts*lambda + 1)^(1/lambda),start=c(2023,11)),pred,pred_l,pred_u,xlab="t",ylab="Prix (Euro/Mwhe)",col=c(1,2,3,3),lty=c(1,1,2,2),lwd=c(1,3,2,2),main="Pr√©vision du prix moyen mensuel de l'√©lectricit√© en Pologne")
```

Voici donc les valeur pr√©dites pour les p√©riodes futures, accompagn√©es de leurs intervalles de confiance √† 95% :

```{r}
# Calcul des pr√©visions et des intervalles de confiance apr√®s l'inversion de la transformation Box-Cox
pred <- (pred_model$mean * lambda + 1)^(1 / lambda)
pred_l <- (pred_model$lower[, "95%"] * lambda + 1)^(1 / lambda)
pred_u <- (pred_model$upper[, "95%"] * lambda + 1)^(1 / lambda)

# Cr√©ation d'un DataFrame contenant les pr√©dictions et les intervalles de confiance
prediction_df <- data.frame(
  Date = seq(from = as.Date("2024-04-01"), by = "month", length.out = 9),
  Prediction = pred,
  Lower_95_CI = pred_l,
  Upper_95_CI = pred_u
)

# Afficher le DataFrame
print(prediction_df)

```

**Conclusion :**

Au terme de cet exercice 1, nous avons rencontr√© quelques d√©fis et points √† consid√©rer. Le choix de convertir les prix agr√©g√©s par heure en moyenne mensuelle a √©t√© motiv√© par les difficult√©s rencontr√©es lors de la mod√©lisation d'un mod√®le ARMA sur la s√©rie initiale. Celle-ci fluctuait consid√©rablement et pr√©sentait une h√©t√©rosc√©dasticit√© conditionnelle, que le mod√®le ARMA ne pouvait pas ad√©quatement capturer. Ainsi, mon choix s'est port√© sur une agr√©gation pour simplifier l'analyse.

## Exercice II :

## Importation et traitement des donn√©es

Nous allons d√©buter par le chargement et la pr√©paration de donn√©es relatives √† la mortalit√© attribuable √† la pollution, √† la consommation √©nerg√©tique par source, et aux donn√©es d√©mographiques. Notre objectif est d'examiner la corr√©lation entre la mortalit√© et la consommation d'√©nergie par habitant. Pour ce faire, nous fusionnerons ces ensembles de donn√©es, renommerons les colonnes pertinentes, et calculerons la consommation d'√©nergie par habitant pour diverses sources √©nerg√©tiques, tout en √©liminant les donn√©es incompl√®tes.

```{r}
mortalite_pollution = read.csv("death-rate-from-air-pollution-per-100000.csv")


conso_energie = read.csv("energy-consumption-by-source-and-country.csv")


demographic_data = read.csv("population-and-demography.csv")


colnames(mortalite_pollution)[4] = "Morta_100000"


colnames(demographic_data)[1]="Entity"


data = mortalite_pollution  %>% 
  inner_join(demographic_data,by = join_by(Entity, Year))


#Je renomme les colonnes
col_nom = list("Geothermal_Biomass","Biofuels","Solaire","Heolienne","Hydro","Nucleaire","Gaz","Charbon","Petrole")
colnames(conso_energie)[4:12] = col_nom


#jointure
data = data   %>% 
  inner_join(conso_energie,by = join_by(Entity, Code, Year))


# Liste des noms de colonnes √† diviser par la colonne "Population"
columns_to_divide <- c("Geothermal_Biomass", "Biofuels", "Solaire", "Heolienne", "Hydro", "Nucleaire", "Gaz", "Charbon", "Petrole")

# Boucle pour diviser chaque colonne par la colonne "Population"
for (col in columns_to_divide) {
  new_col_name <- paste0(col, "_hbt")  # Nom de la nouvelle colonne
  data[[new_col_name]] <- data[[col]] / data[["Population"]]
}

#Selection des colonnes utile pour la modelisation 
data = data %>% dplyr::select('Entity','Year',"Morta_100000", "Geothermal_Biomass_hbt":"Petrole_hbt")


data = na.omit(data)#Supprimer les valeurs manquantes

head(data)
```

### Visualisation des donn√©es

Avant de nous lancer dans la construction d'un mod√®le, nous allons examiner les donn√©es.

Nous cherchons √† d√©terminer s'il existe une corr√©lation entre les variables.

Observons les nuages de points pour chaque paire de variables.

```{r}
par(mfrow = c(3, 3))  # D√©finit la disposition des graphiques
types_energie <- names(data)[-1:-3]  # Exclure la premi√®re colonne de mortalit√©

for (type in types_energie) {
  plot(data[[type]], data$Morta_100000,
       main = paste(type, "et Mortalit√©"),
       xlab = "Consommation par habitant",
       ylab = "Mortalit√© due √† la pollution",
       pch = 19, col = rgb(0.1, 0.1, 0.8, 0.5))
}
```

Comme on peut le voir ci-dessus, les nuages de points pour chaque paire de variables entre la variable expliqu√©e (Mortalit√©_pollution_par_hbt) et les variables explicatives ne montrent pas de relation lin√©aire claire. Certaines sources d'√©nergie, telles que le solaire et l'√©olien, montrent des concentrations de points √† faible consommation et faible mortalit√©, sugg√©rant un impact moindre sur la pollution. √Ä l'inverse, les combustibles fossiles comme le charbon et le p√©trole pr√©sentent une dispersion plus large, ce qui pourrait indiquer une association plus forte avec des niveaux √©lev√©s de mortalit√© due √† la pollution.

Par cons√©quent, l'utilisation de transformations des variables peut s'av√©rer n√©cessaire.

### Transformation des donn√©es :

Il est n√©cessaire de transformer les donn√©es afin d'am√©liorer la lin√©arit√© des relations entre les variables.

```{r warning=FALSE,message=FALSE}
nuage_de_point = function(data,mapping,...){
  ggplot(data=data,mapping = mapping)+
    geom_jitter()
}

data %>% dplyr::select(-Entity,-Year) %>% 
  ggpairs(lower=list(continuous=wrap(nuage_de_point))) + 
  theme_bw()+
  theme(panel.background = element_rect(fill = "gray97"))
```

Pour la variable d'int√©r√™t, **Morta_100000**, les indicateurs de forme sugg√®rent une distribution asym√©trique √† gauche et √©tal√©e √† droite. Dans ce cas, une transformation logarithmique semble √™tre la meilleure solution.

Pour les variables explicatives **Geothermal_Biomass_hbt, Biofuels_hbt, Solaire_hbt, Heolienne_hbt, Hydro_hbt, et Nucleaire_hbt**, les indicateurs de forme indiquent une distribution asym√©trique √† gauche, rendant une transformation par racine carr√©e appropri√©e.

Quant aux variables explicatives **Gaz_hbt, Charbon_hbt, et Petrole_hbt**, l'analyse sugg√®re une distribution asym√©trique √† gauche et √©tal√©e √† droite, justifiant √©galement l'utilisation d'une transformation logarithmique.

Pour les transformations logarithmiques, √©tant donn√© que le logarithme de z√©ro n'est pas d√©fini, nous ajusterons d'abord les valeurs en ajoutant $10^{-9}$.

Proc√©dons donc √† ces transformations :

```{r}
data_transforme <- data

# Racine carr√©e
columns_to_sqrt <- c("Geothermal_Biomass_hbt", "Biofuels_hbt", "Solaire_hbt", "Heolienne_hbt", "Hydro_hbt", "Nucleaire_hbt")
for (col in columns_to_sqrt) {
  # Calcul de la racine carr√©e et sauvegarde dans la m√™me colonne
  data_transforme[[col]] <- sqrt(data_transforme[[col]])
  #names(data_transforme)[names(data_transforme) == col] <- paste0("S_", col)
}

# Logarithmique
columns_to_log <- c("Morta_100000", "Gaz_hbt", "Charbon_hbt", "Petrole_hbt")
for (col in columns_to_log) {
  # Calcul du logarithme naturel, ajustement pour √©viter le log(0)
  data_transforme[[col]] <- log(data_transforme[[col]] + 1e-9)
  # Changement de nom de la colonne
  #names(data_transforme)[names(data_transforme) == col] <- paste0("L_", col)
}

head(data_transforme)

```

Visualisons le nuage de points des donn√©es transform√©es :

```{r}
par(mfrow = c(3, 3))  # D√©finit la disposition des graphiques
types_energie <- names(data_transforme)[-1:-3]  # Exclure la premi√®re colonne de mortalit√©

#col_nom = c("S_Geothermal_Biomass_hbt", "S_Biofuels_hbt", "S_Solaire_hbt", "S_Heolienne_hbt", "S_Hydro_hbt", "S_Nucleaire_hbt", "L_Gaz_hbt", "L_Charbon_hbt", "L_Petrole_hbt")

for (type in col_nom) {
   type <- paste0(type, "_hbt") 
  plot(data_transforme[[type]], data_transforme$Morta_100000,
       main = paste(type, "et Mortalit√©"),
       xlab = "Consommation par habitant",
       ylab = "Mortalit√© due √† la pollution",
       pch = 19, col = rgb(0.1, 0.1, 0.8, 0.5))
}
```

Sur ce nuage de points, la relation observ√©e n‚Äôest plus aussi complexe qu'auparavant.

### Mod√®le de r√©gression lin√©aire

```{r}
model = lm(data = data_transforme,Morta_100000~.-Entity-Year)
summary(model)
```

\
Le mod√®le r√©v√®le un $R^{2}$ de 0.8117, ce qui signifie qu'il capture approximativement 81 % de la variabilit√© dans les donn√©es relatives √† la mortalit√© attribuable √† la pollution atmosph√©rique.

Pour √©valuer l'efficacit√© globale du mod√®le, nous utilisons un test F :

-   **Hypoth√®se nulle (H0)** : Aucune des variables ind√©pendantes n'influence la variable d√©pendante.

-   **Hypoth√®se alternative (H1)** : Au moins une variable ind√©pendante influence significativement la variable d√©pendante.

Avec une statistique F de **642** sur 9 et **1340** degr√©s de libert√© et une p-valeur bien en de√ß√† de 2.2√ó10‚àí16, bien inf√©rieure au seuil de **5 %**, nous rejetons l'hypoth√®se nulle. Par cons√©quent, nous concluons que certaines des variables ind√©pendantes ont un effet notable sur la mortalit√© due √† la pollution de l'air.

Concernant le test de significativit√© des coefficients individuels, nos hypoth√®ses sont :

-   **Hypoth√®se nulle (H0)** : Le coefficient d'une variable ind√©pendante est √©gal √† z√©ro, impliquant qu'elle n'a pas d'impact sur la variable d√©pendante.

-   **Hypoth√®se alternative (H1)** : Le coefficient d'une variable ind√©pendante est diff√©rent de z√©ro, sugg√©rant un impact sur la variable d√©pendante.

Dans l'√©valuation de la significativit√© des coefficients du mod√®le, on utilise la distribution t de Student comme r√©f√©rence pour la statistique de test. Des variables telles que **Geothermal_Biomass_hbt, Heolienne_hbt, Gaz_hbt,Solaire_hbt, Charbon_hbt, Hydro_hbt et Petrole_hbt** pr√©sentent des p-valeurs inf√©rieures au seuil de 5%, ce qui indique, qu'elles exercent une influence significative sur la mortalit√© attribuable √† la pollution de l'air. √Ä l'oppos√©, les variables Biofuel_hbt et Nucleaire_hbt, dont les p-valeurs d√©passent le seuil de 5%, ne semblent pas avoir d'effet significatif sur la mortalit√© caus√©e par la pollution de l'air.

Voici une interpr√©tation pratique des coefficients estim√©s :

-   **Geothermal_Biomass_hbt (transform√©e par racine carr√©e):**

    Pour chaque augmentation d'une unit√© de la racine carr√©e de Geothermal_Biomass_hbt, log de Morta_100000 est attendu de diminuer de 506.5 unit√©s, toutes choses √©gales par ailleurs. Ce coefficient est statistiquement significatif.

-   **Biofuels_hbt (transform√©e par racine carr√©e):**

    Pour chaque augmentation d'une unit√© de la racine carr√©e de Biofuels_hbt, log de Morta_100000 est attendu d'augmenter de 25.54 unit√©s, toutes choses √©gales par ailleurs. Cependant, cette variable n'est pas statistiquement significative puisque la valeur p est sup√©rieure √† 0.05.

-   **Solaire_hbt et Heloienne_hbt (transform√©es par racine carr√©e):**

    Pour chaque augmentation d'une unit√© de la racine carr√©e de Solaire_hbt, log de Morta_100000 est attendu de diminuer de 303.5 unit√©s, toutes choses √©gales par ailleurs. Ce coefficient est statistiquement significatif.

-   **Hydro_hbt (transform√©e par racine carr√©e):**

    Pour chaque augmentation d'une unit√© de la racine carr√©e de Hydro_hbt, log de Morta_100000 est attendu de diminuer de 143 unit√©s, toutes choses √©gales par ailleurs. Ce coefficient est statistiquement significatif.

-   **Nucleaire_hbt (transform√©e par racine carr√©e):**

    Pour chaque augmentation d'une unit√© de la racine carr√©e de Nucleaire_hbt, log de Morta_100000 est attendu d'augmenter de 10.38 unit√©s, toutes choses √©gales par ailleurs. Ce coefficient n'est pas statistiquement significatif.

-   **Gaz_hbt (transform√©e par logarithme):**

    Si Gaz_hbt augmente de 1 (apr√®s transformation logarithmique), log de Morta_100000 est attendu de diminuer de 0.02591 unit√©s, toutes choses √©gales par ailleurs. Ce coefficient est statistiquement significatif.

-   **Charbon_hbt et Petrole_hbt (transform√©es par logarithme):**

    Si Charbon_hbt augmente de 1 (apr√®s transformation logarithmique), log de Morta_100000 est attendu de diminuer de 157.4 unit√©s, toutes choses √©gales par ailleurs. Ce coefficient est statistiquement significatif.

-   **Petrole_hbt (transform√©es par logarithme)**: Si Petrole_hbt augmente de 1 (apr√®s transformation logarithmique), log de Morta_100000 est attendu de diminuer de 56.59 unit√©s, toutes choses √©gales par ailleurs. Ce coefficient est statistiquement significatif.

-   **Heolienne_hbt (transform√©e par racine carr√©e)**: Pour chaque augmentation d'une unit√© de la racine carr√©e de Heolienne_hbt, log de Morta_100000 est attendu de diminuer de 448.2 unit√©s, toutes choses √©gales par ailleurs. Ce coefficient est statistiquement significatif.

#### Elimination d'information redondante dans mon mod√®le

Avant de proc√©der √† la s√©lection du mod√®le, il est crucial de retirer toute redondance parmi les variables explicatives. Id√©alement, ces variables devraient √™tre ind√©pendantes les unes des autres pour √©viter des probl√®mes de multicollin√©arit√©. Afin d'identifier et d'√©liminer toute corr√©lation excessive entre elles, l'utilisation du facteur d'inflation de la variance (VIF) est recommand√©e. Un seuil VIF de 3 sera adopt√© pour d√©terminer l'ind√©pendance ad√©quate entre les variables, en dessous duquel les variables seront consid√©r√©es comme suffisamment ind√©pendantes pour √™tre incluses dans le mod√®le.

```{r}
vif(model)
```

√âtant donn√© que les valeurs du facteur d'inflation de la variance (VIF) pour toutes les variables sont inf√©rieures √† 3, il est possible d'affirmer que le mod√®le ne pr√©sente pas de redondance informative significative. Autrement dit, les variables explicatives ne montrent pas de multicollin√©arit√© notable, ce qui renforce la validit√© du mod√®le pour la poursuite des analyses.

**Selection de mod√®le (backward) selon le crit√®re d'information AIC**

Nous allons maintenant entreprendre la s√©lection du mod√®le en utilisant la m√©thode de suppression progressive, ou "backward elimination". Cette approche consiste √† commencer avec un mod√®le comprenant toutes les variables explicatives potentielles, puis √† les √©liminer une par une, en retirant √† chaque √©tape la variable qui a le moins d'impact sur la performance du mod√®le, jusqu'√† ce que seules les variables les plus significatives demeurent.

```{r}
step_backward <- step(model, direction = 'backward')
```

√Ä l'issue de la s√©lection de mod√®le par √©limination arri√®re, il appara√Æt que les variables **Biofuels_hbt et Nucleaire_hbt** ont √©t√© retir√©es. Nous disposons d√©sormais d'un mod√®le √©pur√© qui ne retient que les variables ayant le plus d'influence significative.

```{r}
model = step_backward
summary(model)
```

Le $R^{2}$ de **0.8115** reste pratiquement inchang√©, indiquant une forte capacit√© explicative du mod√®le final. Dans ce mod√®le, tous les coefficients sont statistiquement significatifs avec un seuil de confiance de 5%.

Ainsi, nous avons √©labor√© un mod√®le de r√©gression lin√©aire qui explique efficacement la mortalit√© due √† la pollution de l'air en fonction de la consommation de certains types d'√©nergie. La prochaine √©tape consiste √† valider ce mod√®le pour confirmer sa fiabilit√© et son applicabilit√©.

### Validation de mod√®le

Pour assurer la validit√© de notre mod√®le de r√©gression lin√©aire, il est crucial de proc√©der √† une analyse approfondie des r√©sidus. Cette analyse comprend la v√©rification de la normalit√© des r√©sidus, l'homosc√©dasticit√© (constance de la variance des r√©sidus), et l'absence de corr√©lation entre eux. Il est √©galement important d'identifier toute valeur aberrante ou point d'influence potentiel et, si possible, d'examiner ces √©l√©ments de plus pr√®s pour √©valuer leur impact sur le mod√®le.

-   **Normalit√© des r√©sidus :**

Examinons le graphique QQ des r√©sidus pour √©valuer leur distribution.

```{r}
qqnorm(model$residuals)
qqline(model$residuals)
```

Le QQ-plot des r√©sidus r√©v√®le des √©carts par rapport √† la ligne th√©orique, en particulier aux extr√©mit√©s, ce qui sugg√®re une possible non-normalit√© des r√©sidus. Pour v√©rifier cette observation de mani√®re formelle, nous allons proc√©der au test de Shapiro-Wilk :

1.  **Hypoth√®se nulle (H0)** : Les r√©sidus suivent une distribution normale.

2.  **Hypoth√®se alternative (H1)** : Les r√©sidus ne suivent pas une distribution normale.

Ce test nous permettra de confirmer statistiquement si la normalit√© des r√©sidus peut √™tre assum√©e pour le mod√®le de r√©gression.

```{r}
shapiro.test(model$residuals)
```

Nous obtenons une p-valeur inf√©rieure √† 5%, ce qui nous conduit √† rejeter l'hypoth√®se nulle (H0). Par cons√©quent, nous concluons que les r√©sidus ne suivent pas une distribution normale, indiquant que le test de normalit√© n'est pas satisfait pour ce mod√®le.

-   **Homosc√©dascticit√©**

Examinons le graphique des r√©sidus par rapport aux valeurs pr√©dites. Ce type de graphique est utile pour v√©rifier l'homosc√©dasticit√© des r√©sidus, c'est-√†-dire pour s'assurer que la variance des erreurs de pr√©diction reste constante √† travers les valeurs pr√©dites.

```{r}
# Calcul des r√©sidus et des valeurs pr√©dites
residuals <- residuals(model)
fitted_values <- fitted(model)

# Graphique des r√©sidus par rapport aux valeurs pr√©dites
plot(fitted_values, residuals, xlab = "Valeurs Pr√©dites", ylab = "R√©sidus",
     main = "R√©sidus vs Valeurs Pr√©dites", pch = 20, col = "blue")
abline(h = 0, lty = 2, col = "red")
```

Les r√©sidus sont r√©partis de mani√®re relativement uniforme autour de la ligne horizontale √† z√©ro, sans montrer de tendance ou de motif particulier dans leur dispersion. Ce comportement sugg√®re que les r√©sidus de notre mod√®le sont homosc√©dastiques, c'est-√†-dire que la variance des erreurs reste constante √† travers les diff√©rentes valeurs pr√©dites, ce qui est un bon indicateur de la fiabilit√© du mod√®le de r√©gression.

-   **Corr√©lation des r√©sidus**

\
Pour √©valuer l'ind√©pendance des r√©sidus, nous utiliserons le test de Durbin-Watson, qui est sp√©cialement con√ßu pour d√©tecter la pr√©sence d'autocorr√©lation s√©rielle √† l'ordre 1 dans les r√©sidus d'un mod√®le de r√©gression lin√©aire.

Les hypoth√®ses du test de Durbin-Watson sont les suivantes :

1.  **Hypoth√®se nulle (H0)** : Il n'y a pas d'autocorr√©lation des r√©sidus.

2.  **Hypoth√®se alternative (H1)** : Il existe une autocorr√©lation des r√©sidus.

```{r}
dwtest(model)
```

Il semble que la p-valeur obtenue du test de **Durbin-Watson** soit inf√©rieure √† 5%, ce qui nous conduit √† rejeter l'hypoth√®se nulle (H0). Ainsi, nous concluons que les r√©sidus de notre mod√®le pr√©sentent une autocorr√©lation, indiquant que les r√©sidus sont corr√©l√©s entre eux.

Cela signifie qu'il existe de l'information dans les r√©sidus que notre mod√®le actuel ne parvient pas √† capturer.

Les r√©sidus de notre mod√®le ne respecte pas les hypoth√®ses d'un mod√®le de r√©gression lin√©aire.

-   **D√©tection de valeurs aberrantes et de points influents (Cook's Distance )**

**D√©tection des points aberrants ou outliers** :

```{r}
outliers = model %>% outlierTest()
print(outliers)
```

On a donc un point aberrants au vu du seuil de significativit√© de 5%.

```{r}
outlier_data <- data[outliers$rstudent, ]
outlier_data
```

Ce qui correspond √† l'observation de l'argentine en 2013.

**D√©tection des points influents :**

```{r}
influent = model %>% influencePlot()
print(influent)
```

Nous constatons que tous les points influents identifi√©s ne sont pas n√©cessairement des valeurs aberrantes. Parmi eux, quatre se d√©marquent, et un seul est consid√©r√© comme un outlier.

Face √† cette observation, il est essentiel de se demander si ces anomalies proviennent d'erreurs dans la collecte des donn√©es ou si elles repr√©sentent des observations v√©ridiques. Cette distinction est cruciale pour la validit√© et la fiabilit√© de notre analyse.

### Conclusion :

En conclusion, le mod√®le de r√©gression lin√©aire que nous avons utilis√© ne se r√©v√®le pas fiable, car il ne respecte pas les hypoth√®ses fondamentales requises pour un mod√®le de r√©gression lin√©aire. Les probl√®mes d'autocorr√©lation des r√©sidus, de non-normalit√© et d'homosc√©dasticit√© non respect√©e indiquent que le mod√®le pourrait √™tre am√©lior√© ou qu'une autre approche de mod√©lisation pourrait √™tre n√©cessaire pour obtenir des r√©sultats plus robustes et fiables.
